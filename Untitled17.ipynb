{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled17.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6w0A9kKLoW3F"
      },
      "source": [
        "def read(path):\n",
        "    with open(path) as f:\n",
        "        captions = f.read()\n",
        "    return captions\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFJZ1nhGoe_R"
      },
      "source": [
        "captions= read(\"./abc.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jo6nofEXooH6"
      },
      "source": [
        "captions=(captions.split(\"\\n\"))\n",
        "print(captions[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaxhQLLboqZQ"
      },
      "source": [
        "s,t=captions[0].split(\"\\t\")\n",
        "print(s.split(\".\")[0])\n",
        "print(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ND1j8e50os3d"
      },
      "source": [
        "dic = {}\n",
        "for x in captions:\n",
        "    \n",
        "    first = x.split('\\t')\n",
        "    img_name = (first[0].split(\".\")[0])\n",
        "   \n",
        "    \n",
        "    if dic.get(img_name) is None:\n",
        "        dic[img_name] = []\n",
        "        \n",
        "    dic[img_name].append(first[-1])\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1F4jpo3Cov9A"
      },
      "source": [
        "img_path=\"C:/Users/RAHUL/Desktop/ghi\"\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "img=cv2.imread(\"C:/Users/RAHUL/Desktop/gh/1000268201_693b08cb0e.jpg\")\n",
        "img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpJ3BjjMoyfJ"
      },
      "source": [
        "import re\n",
        "def clean(sentence):\n",
        "    sentence = sentence.lower()\n",
        "    sentence= re.sub(\"[^a-z]+\",\" \",sentence)\n",
        "    sentence = sentence.split()\n",
        "    sentence=[s for s in sentence if len(s)>1]\n",
        "    sentence=\" \".join(sentence)\n",
        "    return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NsqYYBeo04I"
      },
      "source": [
        "for key,caption_list in dic.items():\n",
        "    for i in range(len(caption_list)):\n",
        "        caption_list[i] = clean(caption_list[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wu8JrEAMo1if"
      },
      "source": [
        "vocab=set()\n",
        "for key in dic.keys():\n",
        "    [vocab.update(sentence.split()) for sentence in dic[key]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13bLwRJTo7qp"
      },
      "source": [
        "vocab=set()\n",
        "for key in dic.keys():\n",
        "    [vocab.update(sentence.split()) for sentence in dic[key]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkGhq4zoo_JA"
      },
      "source": [
        "total_words = []\n",
        "for key in dic.keys():\n",
        "    #[total_words.append(i) for des in dict[key] for i in des.split()]\n",
        "    for des in dic[key]:\n",
        "        for i in des.split():\n",
        "            total_words.append(i)\n",
        "            "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_4aMEA5pBRy"
      },
      "source": [
        "import collections\n",
        "counter = collections.Counter(total_words)\n",
        "#freq_count=dict(counter)\n",
        "print(len(counter.keys()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myV_asRIpDnd"
      },
      "source": [
        "orted_freq_cnt =sorted(counter.items(),reverse=True,key=lambda x:x[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Afd1_zhpG1V"
      },
      "source": [
        "sorted_freq_cnt = [x for x  in sorted_freq_cnt if float(x[1])>10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oC4w4LepJO1"
      },
      "source": [
        "sorted_freq_cnt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOhmqPHwpLkM"
      },
      "source": [
        "total_words=[x[0] for x in sorted_freq_cnt   ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02rZ9-C3pN-b"
      },
      "source": [
        "total_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBCEwtjrpQGQ"
      },
      "source": [
        "train = read(\"./Flickr_8k.trainImages.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqy5nGkOpUWA"
      },
      "source": [
        "print(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgdNuvnLpXVr"
      },
      "source": [
        "test=read(\"./Flickr_8k.testImages.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgLIS3TDpaQh"
      },
      "source": [
        "train_a=[row.split(\".\")[0] for row in train.split(\"\\n\")[:-1]]\n",
        "test_a=[row.split(\".\")[0] for row in test.split(\"\\n\")[:-1]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbE6OFt9pc2e"
      },
      "source": [
        "train_dict={}\n",
        "\n",
        "for t in train_a:\n",
        "    train_dict[t]=[]\n",
        "    for cap in dic[t]:\n",
        "        cap_to_append=\"start \" + cap +\" end\"\n",
        "        train_dict[t].append(cap_to_append)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDOrBf40pe2r"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7lkBNZZpe9i"
      },
      "source": [
        "import tensorflow as tf\n",
        "config = tf.compat.v1.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "sess = tf.compat.v1.Session(config=config)\n",
        "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from keras.preprocessing import image\n",
        "\n",
        "\n",
        "model = ResNet50(weights=\"imagenet\", input_shape=(224,224,3) )\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsIlX0Jwpj1b"
      },
      "source": [
        "from keras.models import Model,load_model\n",
        "import numpy as np\n",
        "#import tensorflow as tf\n",
        "model_new= Model(model.input,model.layers[-2].output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoBLJD9mpmPr"
      },
      "source": [
        "def preprocess(img):\n",
        "    img= image.load_img(img,target_size=(224,224))\n",
        "    img=image.img_to_array(img)\n",
        "    img= np.expand_dims(img,axis=0)\n",
        "    img=preprocess_input(img)\n",
        "    return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOrnSz-hpogG"
      },
      "source": [
        "def encode(img):\n",
        "    img= preprocess(img)\n",
        "    f_ve=model_new.predict(img)\n",
        "    f_ve=f_ve.reshape((-1, ))\n",
        "    #print(f_ve.shape)\n",
        "    return f_ve"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBZz5OV8pqrA"
      },
      "source": [
        "import tensorflow as tf\n",
        "config = tf.compat.v1.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "sess = tf.compat.v1.Session(config=config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXln9gDjps-2"
      },
      "source": [
        "#import time\n",
        "#start=time()\n",
        "encoding_train={}\n",
        "for i,j in enumerate(train_a):\n",
        "    path=\"C:/Users/RAHUL/Desktop/gh\"+\"/\"+j+\".jpg\"\n",
        "    \n",
        "    encoding_train[j]=encode(path)\n",
        "    \n",
        "    if i%100==0:\n",
        "         print(i)\n",
        "        \n",
        "#end_t=time()\n",
        "#print(end_t-start)\n",
        "                  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BX96MaJpva9"
      },
      "source": [
        "import pickle\n",
        "with open(\"encoded_train.pk1\",\"wb\") as f:\n",
        "    pickle.dump(encoding_train,f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5t90ZM5pxVP"
      },
      "source": [
        "filename = 'encoded_train.pk1'\n",
        "pickle.dump(encoding_train, open(filename, 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQLdwhdXpzUa"
      },
      "source": [
        "loaded_model = pickle.load(open('encoded_train.pk1', 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbxPIxzFp2Qj"
      },
      "source": [
        "encoding_test={}\n",
        "for i,j in enumerate(test_a):\n",
        "    path=\"C:/Users/RAHUL/Desktop/gh\"+\"/\"+j+\".jpg\"\n",
        "    \n",
        "    encoding_test[j]=encode(path)\n",
        "    \n",
        "    if i%100==0:\n",
        "         print(i)\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dnm2pOLbp4cF"
      },
      "source": [
        "import pickle\n",
        "with open(\"encoded_test.pk1\",\"wb\") as f:\n",
        "    pickle.dump(encoding_test,f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2YmbFpkp6Vh"
      },
      "source": [
        "word_to_index={}\n",
        "idx_to_word={}\n",
        "for i,word in enumerate(total_words):\n",
        "    word_to_index[word]=i+1\n",
        "    idx_to_word[i+1]=word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dwng6sup8YF"
      },
      "source": [
        "idx_to_word[1846]='start'\n",
        "word_to_index['start']=1846\n",
        "\n",
        "idx_to_word[1847]='end'\n",
        "word_to_index['end']=1847\n",
        "print(len(word_to_index))\n",
        "\n",
        "vocab_size=(len(word_to_index) +2)\n",
        "print(vocab_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dt8bkkYbqAgf"
      },
      "source": [
        "max_len=0\n",
        "for key in train_dict.keys():\n",
        "    for cap in train_dict[key]:\n",
        "        max_len=max(max_len,len(cap.split()))\n",
        "        \n",
        "        \n",
        "print(max_len)        \n",
        "        \n",
        "        \n",
        "        \n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWYg3bdIqDnM"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "def data_generator(train_dict,encoding_train,word_to_index,max_len,batch_size):\n",
        "    \n",
        "    x1,x2,y=[],[],[]\n",
        "    \n",
        "    n=0\n",
        "    while True:\n",
        "        for key,desc_list in train_dict.items():\n",
        "            n+=1\n",
        "            \n",
        "            photo=encoding_train[key]\n",
        "            for desc in desc_list:\n",
        "                seq = [word_to_index[word] for word in desc.split()  if word in word_to_index]\n",
        "                for i in range(1,len(seq)):\n",
        "                    xi=seq[0:i]\n",
        "                    yi=seq[i]\n",
        "                    \n",
        "                    xi=pad_sequences([xi],maxlen=max_len,value=0,padding='post')[0]\n",
        "                    yi=to_categorical([yi],num_classes=vocab_size)[0]\n",
        "                    \n",
        "                    x1.append(photo)\n",
        "                    x2.append(xi)\n",
        "                    y.append(yi)\n",
        "            if n==batch_size:\n",
        "                yield[[np.array(x1),np.array(x2)],np.array(y)]\n",
        "                x1,x2,y=[],[],[]\n",
        "                n=0\n",
        "                    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0idQdsrGqGVc"
      },
      "source": [
        "f= open(\"./glove.6B.50d.txt\",encoding='utf8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKFHv8EkqJAd"
      },
      "source": [
        "import numpy as np\n",
        "embedding_index={}\n",
        "for line in f:\n",
        "    values=line.split()\n",
        "    print(values)\n",
        "    word=values[0]\n",
        "    word_embedding=np.array(values[1:],dtype='float')\n",
        "    embedding_index[word]=word_embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERmcCZ4pqLRN"
      },
      "source": [
        "def get_embedding_matrix():\n",
        "    emb_dim = 50\n",
        "    matrix=np.zeros((vocab_size,emb_dim))\n",
        "    for word,idx in word_to_index.items():\n",
        "        embedding_vector=embedding_index.get(word)\n",
        "        \n",
        "        if embedding_vector is not None:\n",
        "            matrix[idx]=embedding_vector\n",
        "            \n",
        "    return matrix       "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mH7nDOtcqMHv"
      },
      "source": [
        "embedding_matrix=get_embedding_matrix()\n",
        "embedding_matrix.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1pGbke1qOrZ"
      },
      "source": [
        "from keras.layers import Dense,Dropout,Input,Embedding,LSTM,add\n",
        "\n",
        "\n",
        "input_img_features=Input(shape=(2048, ))\n",
        "input_img1=Dropout(0.3)(input_img_features)\n",
        "input_img2=Dense(256,activation='relu')(input_img1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FCdRuewqTfe"
      },
      "source": [
        "input_captions=Input(shape=(max_len,))\n",
        "inp_cap1 = Embedding(input_dim=vocab_size,output_dim=50,mask_zero=True)(input_captions)\n",
        "inp_cap2=Dropout(0.3)(inp_cap1)\n",
        "inp_cap3=LSTM(256)(inp_cap2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZ0BJlc9qVp5"
      },
      "source": [
        "decoder1=add([input_img2,inp_cap3])\n",
        "decoder2=Dense(256,activation='relu')(decoder1)\n",
        "outputs=Dense(vocab_size,activation='softmax')(decoder2)\n",
        "model=Model(inputs=[input_img_features,input_captions],outputs=outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZrzM7M4qYOk"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdS3gb-Jqabk"
      },
      "source": [
        "model.layers[2].set_weights([embedding_matrix])\n",
        "model.layers[2].trainable=False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHQGhpJ9qc-N"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer=\"adam\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8WX96l8qfZi"
      },
      "source": [
        "epochs=20\n",
        "batch_size=3\n",
        "number_pics_per_batch=3\n",
        "steps=len(train_dict)//number_pics_per_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWwpPYeVqhTH"
      },
      "source": [
        "def train():\n",
        "    for i in range(epochs):\n",
        "        generator=data_generator(train_dict,encoding_train,word_to_index,max_len,batch_size)\n",
        "        model.fit_generator(generator,epochs=1,steps_per_epoch=steps,verbose=1)\n",
        "        #model.save('./model_weights'+str(i)+'.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H379XJEFqkUI"
      },
      "source": [
        "def predict(photo):\n",
        "    in_text=\"start\"\n",
        "    for i in range(max_len):\n",
        "        sequence=[word_to_index[w] for w in in_text.split() if w in word_to_index]\n",
        "        sequence=pad_sequences([sequence],maxlen=max_len,padding='post')\n",
        "        ypred=model1.predict([photo,sequence])\n",
        "        ypred = ypred.argmax()\n",
        "        word= idx_to_word[ypred]\n",
        "        in_text+=' ' + word\n",
        "        if word == \"end\":\n",
        "            break\n",
        "    final_caption = in_text.split()[1:-1]\n",
        "    final_caption=' '.join(final_caption)\n",
        "    \n",
        "    return final_caption\n",
        "\n",
        "            "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eODJ5-uFqm1a"
      },
      "source": [
        "import pyttsx3\n",
        "engine = pyttsx3.init()\n",
        "voices = engine.getProperty('voices')\n",
        "engine.setProperty('voice', voices[1].id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vj0tkInHqpN3"
      },
      "source": [
        "for i in range(50):\n",
        "    no= np.random.randint(0,1000)\n",
        "    all_img_names = list(encoding_test.keys())\n",
        "    img_name=all_img_names[i]\n",
        "    photo_2048= encoding_test[img_name].reshape((1,2048))\n",
        "    i=plt.imread(\"C:/Users/RAHUL/Desktop/gh/\"+img_name+\".jpg\")\n",
        "    caption=predict(photo_2048)\n",
        "    engine.say(caption)\n",
        "    engine.runAndWait()\n",
        "    print(caption)\n",
        "    plt.imshow(i)    \n",
        "    plt.axis(\"off\")\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}