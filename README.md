# Ai-bot-vision
Introduction: It will be very good for those persons who canâ€™t see, for them we developed this 
model.

Working Procedure:
We use here some images and RESONET model to extract features and use RNN to get the 
understanding of sentences and then use Dense layer, build matrix to pass through the model and
get the output.
GitHub link: https://github.com/Rahul-132/ai-bot
 Github link
Notebook and code are available in GitHub, also the data is uploaded.
Result: Over 80% accuracy we achieved through this model




We tried to develop a model to help blind people so that this can generate captions and tell people what they can't see.



![image](https://user-images.githubusercontent.com/64769085/123532816-2ee29200-d72e-11eb-9c2c-635db09b2e14.png)



here "dog Jumps in pool" is caption generated from image and that can be heard.



![image](https://user-images.githubusercontent.com/64769085/123532892-d9f34b80-d72e-11eb-8e11-b06e5042ae06.png)


Here "two dogs are running through the snow" is caption.



So we are using a python library to use machinary voice and get sound from the vision. 
